services:
  qdrant:
    image: qdrant/qdrant:v1.16.2
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
      args:
        TORCH_FLAVOR: ${TORCH_FLAVOR:-cpu}
        TORCH_VERSION: ${TORCH_VERSION:-2.5.1}
    image: ootd-backend:local
    working_dir: /app/backend
    volumes:
      - ./:/app
      - hf_cache:/root/.cache/huggingface
    environment:
      - JOB_STATE_FILE=/app/data/job_state.json
      - ASSET_ROOT=/app/data/assets
      - PUBLIC_BASE_URL=http://localhost:8000
      - ENABLE_REAL_RENDER=0
      - YOUTUBE_UPLOAD_REQUIRED=0
      - YOUTUBE_PRIVACY_STATUS=unlisted
      - QDRANT_ENABLED=1
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=musinsa_catalog
      - SEMANTIC_EMBEDDING_BACKEND=${SEMANTIC_EMBEDDING_BACKEND:-clip}
      - CLIP_MODEL_NAME=${CLIP_MODEL_NAME:-openai/clip-vit-base-patch16}
      - CLIP_DEVICE=${CLIP_DEVICE:-auto}
      - HF_HUB_OFFLINE=${HF_HUB_OFFLINE:-0}
      - TRANSFORMERS_OFFLINE=${TRANSFORMERS_OFFLINE:-0}
    command: >
      uvicorn app.main:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    depends_on:
      - qdrant

  frontend:
    image: node:20-alpine
    working_dir: /app/frontend
    volumes:
      - ./frontend:/app/frontend
      - frontend_node_modules:/app/frontend/node_modules
      - frontend_next:/app/frontend/.next
    environment:
      - NEXT_PUBLIC_API_BASE=http://localhost:8000
    command: >
      sh -lc "npm ci --no-audit --no-fund && rm -rf .next/* && npm run dev -- --hostname 0.0.0.0 --port ${FRONTEND_PORT:-3005}"
    ports:
      - "${FRONTEND_PORT:-3005}:${FRONTEND_PORT:-3005}"
    depends_on:
      - backend

volumes:
  qdrant_data:
  hf_cache:
  frontend_node_modules:
  frontend_next:
